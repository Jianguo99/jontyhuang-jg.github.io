<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts | Academic</title><link>https://jontyhuang-jg.github.io/post/</link><atom:link href="https://jontyhuang-jg.github.io/post/index.xml" rel="self" type="application/rss+xml"/><description>Posts</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 22 Feb 2023 10:01:51 +0800</lastBuildDate><image><url>https://jontyhuang-jg.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Posts</title><link>https://jontyhuang-jg.github.io/post/</link></image><item><title>Review of Neural Operator</title><link>https://jontyhuang-jg.github.io/post/review-of-neural-operator/</link><pubDate>Wed, 22 Feb 2023 10:01:51 +0800</pubDate><guid>https://jontyhuang-jg.github.io/post/review-of-neural-operator/</guid><description>&lt;h1 id="1-physics-informed-models">1 Physics-informed models&lt;/h1>
&lt;p>Physics-informed主要是体现了一种将物理信息嵌入到神经网络中的思想，可以和纯数据驱动的方法有效结合。例如：PINN，PCNN。 这类方法的优势是可解释性强，但是落地难度较高。&lt;/p>
&lt;h1 id="2-finite-neural-operator">2 Finite Neural Operator&lt;/h1>
&lt;p>针对某一个特定的方程（初边值确定，参数确定），利用机器学习模型去逼近解函数。由于模型只能一个解函数的逼近，所以称为有限算子。PINN也就是其中一种。&lt;/p>
&lt;h1 id="3-infinite-neural-operator">3 Infinite Neural Operator&lt;/h1>
&lt;p>无限维度算子本质思想是构建两个函数空间（Banch space)的映射。 目前，学术界构建神经算子的思想有三大类：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>基于the theorem of Chen and Chen。 该定理证明了神经网络能够逼近任意非线性连续算子或者非线性连续泛函。例如：&lt;a href="https://www.notion.so/Learning-nonlinear-operators-via-DeepONet-based-on-the-universal-approximation-theorem-of-operators-0cbe8e44c7564751846755b4936abb42" target="_blank" rel="noopener">DeepONet&lt;/a>, &lt;a href="https://www.notion.so/Learning-Operators-with-Coupled-Attention-cb840978bdcd441f8a9e3142284f61a3" target="_blank" rel="noopener">Learning Operators with Coupled Attention&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>基于Kernel function的积分变换. The key idea show as following&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>$$
u(x) = \int \mathcal{G}(x,y)f(y)dy\tag{1}
$$&lt;/p>
&lt;p>where $u(x)$ is the solution function and $f(y)$ is the input function. $\mathcal{G}(x,y) $called Kernel function. 例如：&lt;a href="https://www.notion.so/Neural-Operator-Graph-Kernel-Network-for-Partial-Differential-Equations-a77faed36de649b7902b8418ff4157db" target="_blank" rel="noopener">Graph Kernel Network&lt;/a> , Fourier Neural Network, Koopman neural operator, &lt;a href="https://www.notion.so/Integral-Autoencoder-Network-for-Discretization-Invariant-Learning-0c349257cb6647dbb51bba9b0a94f90a" target="_blank" rel="noopener">IAE-Net&lt;/a>.&lt;/p>
&lt;ul>
&lt;li>大型神经网络直接逼近，无理论基础。
&lt;ul>
&lt;li>基于图神经网络。&lt;/li>
&lt;li>自注意力机制神经网络。&lt;/li>
&lt;li>基于卷积神经网络。 DeepUQ&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="4-basic-knowledge">4 Basic Knowledge&lt;/h1>
&lt;p>&lt;strong>Mesh-independent(resolution-invariant, Mesh-free)&lt;/strong> means that models share the same network parameters between different discretizations of the underlying function spaces and can be used for zero-shot super-resolution. 为了实现这种尺度不变的变换，目前主要是两大类方法。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>pointwise linear transforms. 对输入向量$x$ 的每个元素进行线性变换。坏处就是输入维度和输出维度是一致，同时没用利用到$x$ 的全局信息。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>a parametrized linear integral transformation. 其思想就是式子1。我们写出式子1的离散化形式。&lt;/p>
&lt;p>$$
u(x) = \sum_i \mathcal{G}(x,y_i)f(y_i)
$$&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="5-difficult-issue">5 difficult issue&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>面对不规则解域问题，如何让算法能够解决有同一类方程控制的，但解域不同的问题&lt;/p>
&lt;/li>
&lt;li>
&lt;p>对函数的离散化能否是非等间隔离散化&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="6-appied-porjects">6 Appied Porjects&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://developer.nvidia.com/modulus" target="_blank" rel="noopener">Modulus | NVIDIA Developer&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://www.mindspore.cn/mindflow/docs/zh-CN/r0.1.0-alpha/index.html" target="_blank" rel="noopener">MindFlow介绍 — MindSpore master 文档&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-ai4science/projects/" target="_blank" rel="noopener">Microsoft Research AI4Science&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>机器学习面试总结</title><link>https://jontyhuang-jg.github.io/post/machinelearning/</link><pubDate>Tue, 14 Feb 2023 17:12:59 +0800</pubDate><guid>https://jontyhuang-jg.github.io/post/machinelearning/</guid><description/></item></channel></rss>